{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WARNING\n",
    "\n",
    "### Use deduplicator.ipynb to find and remove such duplicated files:\n",
    "\n",
    "### cars_0001.jpg\n",
    "\n",
    "### cars_0001.jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import glob\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_to_coco(yolo_dir, output_json):\n",
    "    print(\"Starting YOLO to COCO conversion...\")\n",
    "    \n",
    "    # Load data.yaml to get class names\n",
    "    data_yaml = os.path.join(yolo_dir, 'data.yaml')\n",
    "    with open(data_yaml, 'r') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    class_names = data['names']\n",
    "    \n",
    "    # Build categories list\n",
    "    categories = []\n",
    "    for idx, name in enumerate(class_names):\n",
    "        category = {\n",
    "            'id': idx + 1,\n",
    "            'name': name,\n",
    "            'supercategory': ''\n",
    "        }\n",
    "        categories.append(category)\n",
    "\n",
    "    # Initialize COCO JSON structure\n",
    "    coco_json = {\n",
    "        'licenses': [{'name': '', 'id': 0, 'url': ''}],\n",
    "        'info': {'contributor': '', 'date_created': '', 'description': '', 'url': '', 'version': '', 'year': ''},\n",
    "        'categories': categories,\n",
    "        'images': [],\n",
    "        'annotations': []\n",
    "    }\n",
    "\n",
    "    annotation_id = 1\n",
    "    image_id = 1\n",
    "    total_annotations = 0\n",
    "    total_images = 0\n",
    "    \n",
    "    # Dictionary to keep track of file name occurrences\n",
    "    filename_count = defaultdict(int)\n",
    "\n",
    "    # Process images and labels\n",
    "    splits = ['train', 'val', 'test']\n",
    "    for split in splits:\n",
    "        if split in data:\n",
    "            print(f\"\\nProcessing {split} split...\")\n",
    "            images_dir = os.path.join(yolo_dir, data[split].replace('../', ''))\n",
    "            labels_dir = images_dir.replace('images', 'labels')\n",
    "\n",
    "            image_files = glob.glob(os.path.join(images_dir, '*'))\n",
    "            for img_file in tqdm(image_files, desc=f\"Processing {split} images\"):\n",
    "                base_filename = os.path.basename(img_file)\n",
    "                \n",
    "                # Create unique filename\n",
    "                filename_count[base_filename] += 1\n",
    "                if filename_count[base_filename] > 1:\n",
    "                    name, ext = os.path.splitext(base_filename)\n",
    "                    unique_filename = f\"{name}_{filename_count[base_filename]}{ext}\"\n",
    "                else:\n",
    "                    unique_filename = base_filename\n",
    "\n",
    "                img = Image.open(img_file)\n",
    "                width, height = img.size\n",
    "                img_info = {\n",
    "                    'id': image_id,\n",
    "                    'width': width,\n",
    "                    'height': height,\n",
    "                    'file_name': unique_filename,\n",
    "                    'license': 0,\n",
    "                    'flickr_url': '',\n",
    "                    'coco_url': '',\n",
    "                    'date_captured': ''\n",
    "                }\n",
    "                coco_json['images'].append(img_info)\n",
    "                total_images += 1\n",
    "\n",
    "                # Corresponding label file\n",
    "                label_file = os.path.join(labels_dir, os.path.splitext(os.path.basename(img_file))[0] + '.txt')\n",
    "                if os.path.exists(label_file):\n",
    "                    with open(label_file, 'r') as f:\n",
    "                        lines = f.readlines()\n",
    "                    for line in lines:\n",
    "                        parts = line.strip().split()\n",
    "                        if len(parts) >= 5:\n",
    "                            class_id = int(parts[0])\n",
    "                            bbox = [float(x) for x in parts[1:5]]\n",
    "\n",
    "                            # Check if there are more points (segmentation)\n",
    "                            if len(parts) > 5:\n",
    "                                segmentation = [float(x) for x in parts[1:]]\n",
    "                                segmentation_pixel = []\n",
    "                                for idx, point in enumerate(segmentation):\n",
    "                                    if idx % 2 == 0:\n",
    "                                        segmentation_pixel.append(segmentation[idx] * width)\n",
    "                                    else:\n",
    "                                        segmentation_pixel.append(segmentation[idx] * height)\n",
    "                            else:\n",
    "                                x_center, y_center, w, h = bbox\n",
    "                                x_center *= width\n",
    "                                y_center *= height\n",
    "                                w *= width\n",
    "                                h *= height\n",
    "                                x_min = x_center - w / 2\n",
    "                                y_min = y_center - h / 2\n",
    "                                segmentation_pixel = [\n",
    "                                    x_min, y_min,\n",
    "                                    x_min + w, y_min,\n",
    "                                    x_min + w, y_min + h,\n",
    "                                    x_min, y_min + h\n",
    "                                ]\n",
    "\n",
    "                            x_center, y_center, w, h = bbox[:4]\n",
    "                            x_center *= width\n",
    "                            y_center *= height\n",
    "                            w *= width\n",
    "                            h *= height\n",
    "                            x_min = x_center - w / 2\n",
    "                            y_min = y_center - h / 2\n",
    "\n",
    "                            annotation = {\n",
    "                                'id': annotation_id,\n",
    "                                'image_id': image_id,\n",
    "                                'category_id': class_id + 1,\n",
    "                                'segmentation': [segmentation_pixel],\n",
    "                                'area': w * h,\n",
    "                                'bbox': [x_min, y_min, w, h],\n",
    "                                'iscrowd': 0,\n",
    "                                'attributes': {\n",
    "                                    'Damage location': '',\n",
    "                                    'Severity': '',\n",
    "                                    'Recommendation': '',\n",
    "                                    'occluded': False\n",
    "                                }\n",
    "                            }\n",
    "                            coco_json['annotations'].append(annotation)\n",
    "                            annotation_id += 1\n",
    "                            total_annotations += 1\n",
    "                image_id += 1\n",
    "\n",
    "    # Save COCO JSON\n",
    "    with open(output_json, 'w') as f:\n",
    "        json.dump(coco_json, f)\n",
    "    \n",
    "    print(\"\\nConversion completed successfully!\")\n",
    "    print(f\"Total images processed: {total_images}\")\n",
    "    print(f\"Total annotations created: {total_annotations}\")\n",
    "    print(f\"Number of categories: {len(categories)}\")\n",
    "    print(f\"Output saved to: {output_json}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting YOLO to COCO conversion...\n",
      "\n",
      "Processing train split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train images: 100%|██████████| 1025/1025 [00:03<00:00, 266.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing val split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing val images: 100%|██████████| 82/82 [00:00<00:00, 445.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing test split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test images: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conversion completed successfully!\n",
      "Total images processed: 1107\n",
      "Total annotations created: 32566\n",
      "Number of categories: 29\n",
      "Output saved to: instances_default.json\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "yolo_directory = r'C:\\Users\\Sakib\\Desktop\\samples'\n",
    "output_coco_json = 'instances_default.json'\n",
    "\n",
    "yolo_to_coco(yolo_directory, output_coco_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
